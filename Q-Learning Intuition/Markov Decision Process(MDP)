Markov Decision Process
맵에 state에 value를 지정하고 그에 맞는 plan을 깔아두기만 하면 되는 것인가??
그럼 강화학습이 의미가 있는 것인가??

행동 선택에는 두 가지 방식이 있음

Deterministic Search :
이미 정해진 행동 양식이 있어 그 곳에 가면 반드시 그 행동을 하도록 하게 됨 : 100%의 결과가 보장됨

Non-Deterministic Search :
역시 해당 셀마다 추천 행동양식이 있으나 행동은 확률적으로 선택됨
추천 행동의 확률이 높게 배정됨
80%정도는 추천행동의 방향으로 동작이 진행되고
나머지 확률은 지정되지 않은 형태로 진행됨

Markov Process
Markov Decision Process(MDP)

2가지의 개념을 알고 있어야 함

stochastic process (같은 조건에서 여러 번 반복되는 상황들)은
미래 상태의 확률 분포가 오직 현재 상태에만 영향을 받는 조건이라면 (즉 이벤트들의 진행과는 무관하게) Markov property를 갖는데
프로세스가 이와 같은 성질을 갖는 경우 Markov process라고 함

Markov Decision Process : 모델 선택에 필요한(혹은 들어가는) 수학적인 틀을 제공, 부분별로 결과물이 랜덤(무작위)하거나 결정을 내리는 조건에 따라 얻어질 때

Markov Decision Process를 계산할 때 Bellman Equation이 쓰임

deterministic search가 아닌 non-deterministic search가 있으므로
해당 상태에서 존재할 수 있는 모든 결과의 상태들과 그 상태들이 선택될 수 있는 확률이 곱해져 더해진 값...으로 보정

A Survey of Applications of Markov Decision Processes : DJ. White(1993)
